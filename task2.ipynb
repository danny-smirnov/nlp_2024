{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3acb3eb6-b051-4669-8c99-d92ddb8be292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07b416-4924-484b-b01f-09994e1e46f3",
   "metadata": {},
   "source": [
    "# Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "76b9991f-40d6-4acd-869f-a6897c9e4631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Парусная гонка Giraglia Rolex Cup пройдет в Средиземном море в 64-й раз. Победители соревнования, проводимого с 1953 года Yacht Club Italiano, помимо других призов традиционно получают в подарок часы от швейцарского бренда Rolex. Об этом сообщается в пресс-релизе, поступившем в редакцию «Ленты.ру» в среду, 8 мая. Rolex Yacht-Master 40 Фото: пресс-служба Mercury Соревнования будут проходить с 10 по 18 июня. Первый этап: ночной переход из Сан-Ремо в Сен-Тропе 10-11 июня (дистанция 50 морских миль — около 90 километров). Второй этап: серия прибрежных гонок в бухте Сен-Тропе с 11 по 14 июня. Финальный этап пройдет с 15 по 18 июня: оффшорная гонка по маршруту Сен-Тропе — Генуя (243 морских мили — 450 километров). Маршрут проходит через скалистый остров Джиралья к северу от Корсики и завершается в Генуе.Регата, с 1997 года проходящая при поддержке Rolex, считается одной из самых значительных яхтенных гонок в Средиземноморье. В этом году в ней ожидается участие трех российских экипажей.'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process data\n",
    "with open('/Users/dosmirnov/llm_task2/data/news.txt') as f:\n",
    "    data = [x.split('\\t')[-1] for x in f.read().split('\\n')]\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "bddc0400-9821-406a-a297-7171e37127c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['привет', 'как', 'теб', 'зовут']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Normalizer:\n",
    "    def __init__(self):        \n",
    "        self.stemmer = SnowballStemmer('russian')\n",
    "        self.regexp_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "\n",
    "    def normalize(self, text) -> list:\n",
    "        words = self.regexp_tokenizer.tokenize(text)\n",
    "        normalized = [self.stemmer.stem(word) for word in words]\n",
    "        return normalized\n",
    "\n",
    "normalizer = Normalizer()\n",
    "\n",
    "normalizer.normalize('Привет, как тебя зовут?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5c934dfb-2136-4ae0-8fa3-d213ca84eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2vec model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10001/10001 [00:27<00:00, 368.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "class Word2VecTokenizer:\n",
    "    def __init__(self, model=None):\n",
    "        if model:\n",
    "            self.model = model\n",
    "            self.trained = True\n",
    "        else:\n",
    "            self.trained = False\n",
    "\n",
    "        self.normalizer = Normalizer()\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        print('Training word2vec model')\n",
    "        sentences = [normalizer.normalize(sentence) for sentence in tqdm(corpus)]\n",
    "        self.model = Word2Vec(sentences, vector_size=100, window=6, min_count=1, workers=4, sg=0)\n",
    "        self.trained = True\n",
    "\n",
    "    def _vectorize_with_pass(self, sentence):\n",
    "        vectors = []\n",
    "        for w in sentence:\n",
    "            if w in self.model.wv:\n",
    "                vectors.append(self.model.wv[w])\n",
    "        return vectors\n",
    "        \n",
    "\n",
    "    def transform(self, text):\n",
    "        if not self.trained:\n",
    "            raise ValueError('Model should be trained first')\n",
    "\n",
    "        normalized = self.normalizer.normalize(text)\n",
    "        vectors = self._vectorize_with_pass(normalized)\n",
    "\n",
    "        return vectors\n",
    "\n",
    "    @staticmethod\n",
    "    def aggregate(vectors, method='avg'):\n",
    "        avg_functions = {\n",
    "            'avg':partial(np.mean, axis=0),\n",
    "            'max':partial(np.max, axis=0),\n",
    "            'min':partial(np.min, axis=0)\n",
    "        }\n",
    "        return avg_functions[method](vectors)\n",
    "        \n",
    "\n",
    "w2v = Word2VecTokenizer()\n",
    "w2v.fit(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2aceff-1e4f-4beb-8460-f3ee338ae24d",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f145465a-5d08-4472-8e57-0305a7a1983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/dosmirnov/llm_task2/data/news.txt', delimiter='\\t', header=None, names=['label', 'header', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4767d8de-e578-4984-b60b-45a8a7d22e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vectors'] = data['text'].apply(w2v.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "693df960-9922-428c-a398-cdd117899c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>header</th>\n",
       "      <th>text</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>style</td>\n",
       "      <td>Rolex наградит победителей регаты</td>\n",
       "      <td>Парусная гонка Giraglia Rolex Cup пройдет в Ср...</td>\n",
       "      <td>[[-0.10808962, 0.25112814, 0.11802034, 0.19438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sport</td>\n",
       "      <td>Матс Сундин стал советником тренера сборной Шв...</td>\n",
       "      <td>Шведский хоккеист Матс Сундин назначен советни...</td>\n",
       "      <td>[[-0.008370347, 0.3923986, 0.3377372, 0.108342...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>media</td>\n",
       "      <td>Брендом года по версии EFFIE впервые стал город</td>\n",
       "      <td>Гран-при конкурса \"Брэнд года/EFFIE\" получил г...</td>\n",
       "      <td>[[0.10989315, -0.3886318, -0.1304021, 0.092096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>economics</td>\n",
       "      <td>Цена нефти WTI снизилась после публикации данн...</td>\n",
       "      <td>Цена американской нефти WTI на лондонской бирж...</td>\n",
       "      <td>[[1.1869445, -0.44310635, -2.2136948, -2.17737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>economics</td>\n",
       "      <td>Сбербанк распродаст другим банкирам миллиардны...</td>\n",
       "      <td>Сбербанк выставил на продажу долги по 21,4 тыс...</td>\n",
       "      <td>[[1.004313, 0.21267386, -0.05910961, -0.183026...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                             header  \\\n",
       "0      style                  Rolex наградит победителей регаты   \n",
       "1      sport  Матс Сундин стал советником тренера сборной Шв...   \n",
       "2      media    Брендом года по версии EFFIE впервые стал город   \n",
       "3  economics  Цена нефти WTI снизилась после публикации данн...   \n",
       "4  economics  Сбербанк распродаст другим банкирам миллиардны...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Парусная гонка Giraglia Rolex Cup пройдет в Ср...   \n",
       "1  Шведский хоккеист Матс Сундин назначен советни...   \n",
       "2  Гран-при конкурса \"Брэнд года/EFFIE\" получил г...   \n",
       "3  Цена американской нефти WTI на лондонской бирж...   \n",
       "4  Сбербанк выставил на продажу долги по 21,4 тыс...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [[-0.10808962, 0.25112814, 0.11802034, 0.19438...  \n",
       "1  [[-0.008370347, 0.3923986, 0.3377372, 0.108342...  \n",
       "2  [[0.10989315, -0.3886318, -0.1304021, 0.092096...  \n",
       "3  [[1.1869445, -0.44310635, -2.2136948, -2.17737...  \n",
       "4  [[1.004313, 0.21267386, -0.05910961, -0.183026...  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2feb95-2ea6-45c3-a2a2-e0c8de694966",
   "metadata": {},
   "source": [
    "# Try avg aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "b65bfaec-a733-46b1-9dce-f452ce308caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(data['vectors'].apply(partial(w2v.aggregate, method='avg'))),\n",
    "    le.fit_transform(data['label']), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "30756e59-632b-4d75-80dc-45fcb352866d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier = SVC(gamma='auto')\n",
    "classifier.fit(X_train, y_train)\n",
    "f1_score(y_test, classifier.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761d0b8-c0ed-42d8-99ac-e40fdb8a136d",
   "metadata": {},
   "source": [
    "# Try max/min aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e7b53fcf-b3b4-4bd9-836d-9e9fee26aeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5995"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(data['vectors'].apply(partial(w2v.aggregate, method='max'))),\n",
    "    le.fit_transform(data['label']), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier = SVC(gamma='auto')\n",
    "classifier.fit(X_train, y_train)\n",
    "f1_score(y_test, classifier.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "95dd7f25-6e73-42cd-8621-61542e92f811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6185"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(data['vectors'].apply(partial(w2v.aggregate, method='min'))),\n",
    "    le.fit_transform(data['label']), \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier = SVC(gamma='auto')\n",
    "classifier.fit(X_train, y_train)\n",
    "f1_score(y_test, classifier.predict(X_test), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d2b09-0d1c-4f97-b500-90d60982b178",
   "metadata": {},
   "source": [
    "# Bonus: Recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb765e-26dd-445d-9ca0-3d15f2eec2a1",
   "metadata": {},
   "source": [
    "- Решение задачи векторного представления текста и классификации одной сущностью\n",
    "- Контролируемость обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "5101a314-898b-408b-87a1-af0f1da2e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class BasicRNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(BasicRNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu', bidirectional = False)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 8000\n",
    "num_epochs = n_iters / (len(X_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "test = TensorDataset(torch.tensor(X_test),torch.tensor(y_test))\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# Create RNN\n",
    "input_dim = 100    # input dimension\n",
    "hidden_dim = 256  # hidden layer dimension\n",
    "layer_dim = 1   # number of hidden layers\n",
    "output_dim = data['label'].nunique()   # output dimension\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam Optimizer\n",
    "# learning_rate = 0.0005\n",
    "# weight_decay = 1e-4\n",
    "optimizer = torch.optim.AdamW(model.parameters()) #, lr=learning_rate, weight_decay=weight_decay) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aee7555-1025-40ac-9f14-7b85c771580c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_dim = 1  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (texts, labels) in enumerate(train_loader):\n",
    "\n",
    "        train  = Variable(texts.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "            \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 250 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for texts, labels in test_loader:\n",
    "                texts = Variable(texts.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(texts)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "17a010ce-d8df-4dd6-836f-c1e2c1e60d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6045"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, \n",
    "         torch.max(model(Variable(torch.tensor(X_test).view(-1, seq_dim, input_dim))), 1)[1],\n",
    "        average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fafa4-80fa-49d8-98a3-4b1ad8cb8f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
